name: Firecrawl
description: 'A Model Context Protocol (MCP) server that integrates with Firecrawl for web scraping capabilities. Perform web scraping, crawling, search, and content extraction with automatic retries and rate limiting.


  ## Features

  - **Web Scraping**: Extract content from single pages or batch process multiple URLs

  - **Site Discovery**: Map websites to discover all indexed URLs and site structure

  - **Web Search**: Search the web and optionally extract content from search results

  - **Content Crawling**: Comprehensive site crawling with depth control and filtering

  - **Structured Extraction**: Extract specific data using LLM capabilities with JSON schemas

  - **Deep Research**: In-depth, multi-source research with intelligent analysis

  - **Rate Limiting**: Automatic rate limit handling with exponential backoff and retries


  ## What you''ll need to connect


  **Required:**

  - **Firecrawl API Key**: Your Firecrawl API key (visit https://www.firecrawl.dev to get a new key)


  ## Example Usage


  - **Single URL**: Use `scrape`

  - **Multiple URLs**: Use `batch_scrape`

  - **Discover URLs**: Use `map`

  - **Web Search**: Use `search`

  - **Structured Data**: Use `extract`

  - **Whole Site Analysis**: Use `crawl` (with limits!)

  - **In-depth Research**: Use `deep_research`


  ### Quick Reference Table


  | Tool                | Best for                                 | Returns         |

  | ------------------- | ---------------------------------------- | --------------- |

  | scrape              | Single page content                      | markdown/html   |

  | batch_scrape        | Multiple known URLs                      | markdown/html[] |

  | map                 | Discovering URLs on a site               | URL[]           |

  | crawl               | Multi-page extraction (with limits)      | markdown/html[] |

  | search              | Web search for info                      | results[]       |

  | extract             | Structured data from pages               | JSON            |

  | deep_research       | In-depth, multi-source research          | summary, sources|

  | generate_llmstxt    | LLMs.txt for a domain                    | text            |

  '
metadata:
  categories: Retrieval & Search,Automation & Browsers,Science & Research
  source: vendor
icon: https://avatars.githubusercontent.com/u/135057108?v=4
repoURL: https://github.com/firecrawl/firecrawl-mcp-server
toolPreview:
- name: firecrawl_scrape
  description: Scrape content from a single URL with advanced options.
  params:
    actions: List of actions to perform before scraping
    excludeTags: HTML tags to exclude from extraction
    extract: Configuration for structured data extraction
    formats: 'Content formats to extract (default: [''markdown''])'
    includeTags: HTML tags to specifically include in extraction
    location: Location settings for scraping
    maxAge: 'Maximum age in milliseconds for cached content. Use cached data if available and younger than maxAge, otherwise scrape fresh. Enables 500% faster scrapes for recently cached pages. Default: 0 (always scrape fresh)'
    mobile: Use mobile viewport
    onlyMainContent: Extract only the main content, filtering out navigation, footers, etc.
    removeBase64Images: Remove base64 encoded images from output
    skipTlsVerification: Skip TLS certificate verification
    timeout: Maximum time in milliseconds to wait for the page to load
    url: The URL to scrape
    waitFor: Time in milliseconds to wait for dynamic content to load
- name: firecrawl_map
  description: Map a website to discover all indexed URLs on the site.
  params:
    ignoreSitemap: Skip sitemap.xml discovery and only use HTML links
    includeSubdomains: Include URLs from subdomains in results
    limit: Maximum number of URLs to return
    search: Optional search term to filter URLs
    sitemapOnly: Only use sitemap.xml for discovery, ignore HTML links
    url: Starting URL for URL discovery
- name: firecrawl_crawl
  description: Starts an asynchronous crawl job on a website and extracts content from all pages.
  params:
    allowBackwardLinks: Allow crawling links that point to parent directories
    allowExternalLinks: Allow crawling links to external domains
    deduplicateSimilarURLs: Remove similar URLs during crawl
    excludePaths: URL paths to exclude from crawling
    ignoreQueryParameters: Ignore query parameters when comparing URLs
    ignoreSitemap: Skip sitemap.xml discovery
    includePaths: Only crawl these URL paths
    limit: Maximum number of pages to crawl
    maxDepth: Maximum link depth to crawl
    scrapeOptions: Options for scraping each page
    url: Starting URL for the crawl
    webhook: ''
- name: firecrawl_check_crawl_status
  description: Check the status of a crawl job.
  params:
    id: Crawl job ID to check
- name: firecrawl_search
  description: Search the web and optionally extract content from search results.
  params:
    country: 'Country code for search results (default: us)'
    filter: Search filter
    lang: 'Language code for search results (default: en)'
    limit: 'Maximum number of results to return (default: 5)'
    location: Location settings for search
    query: Search query string
    scrapeOptions: Options for scraping search results
    tbs: Time-based search filter
- name: firecrawl_extract
  description: Extract structured information from web pages using LLM capabilities.
  params:
    allowExternalLinks: Allow extraction from external links
    enableWebSearch: Enable web search for additional context
    includeSubdomains: Include subdomains in extraction
    prompt: Prompt for the LLM extraction
    schema: JSON schema for structured data extraction
    systemPrompt: System prompt for LLM extraction
    urls: List of URLs to extract information from
- name: firecrawl_generate_llmstxt
  description: Generate a standardized llms.txt (and optionally llms-full.txt) file for a given domain. This file defines how large language models should interact with the site
  params:
    maxUrls: 'Maximum number of URLs to process (1-100, default: 10)'
    showFullText: Whether to show the full LLMs-full.txt in the response
    url: The URL to generate LLMs.txt from
env:
- key: FIRECRAWL_API_KEY
  name: Firecrawl API Key
  required: true
  sensitive: true
  description: Your Firecrawl API key.
runtime: containerized
containerizedConfig:
  image: ghcr.io/obot-platform/mcp-images/firecrawl:3.5.2
  port: 8099
  path: /
  args:
  - firecrawl-mcp
